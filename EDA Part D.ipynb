{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "import boto3\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "from io import StringIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_partD(path, year):\n",
    "    '''\n",
    "    Input: source path to raw file and year\n",
    "    Process: import table as a pd.DatafFrame and add `year` column\n",
    "    Output: pd.DatafFrame\n",
    "    '''\n",
    "    chunksize = 10 ** 6\n",
    "    chunks_df = []\n",
    "    for chunk in pd.read_csv(path, sep=\"\\t\", low_memory=False, chunksize=chunksize):\n",
    "        chunks_df.append(chunk)\n",
    "    df = pd.concat(chunks_df, axis=0)\n",
    "    # append a year column\n",
    "    df['year'] = pd.Series([year] * len(df))\n",
    "    return df\n",
    "\n",
    "def save_medicare_part_D_to_efs(medicare_df):\n",
    "    '''\n",
    "    read sample: pd.read_csv(efs_path, nrows=5, index_col=0)\n",
    "    '''\n",
    "    efs_path = '~/SageMaker/efs/DrFraud/data/medicare_part_D.csv'\n",
    "    medicare_df.to_csv(efs_path, sep=',')\n",
    "    \n",
    "def save_id_df_to_efs(id_df):\n",
    "    efs_path = '~/SageMaker/efs/DrFraud/data/id_df.csv'\n",
    "    id_df.to_csv(efs_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket='dast1healthcare'\n",
    "\n",
    "path_tuples = [(\"PartD_Prescriber_PUF_NPI_Drug_13.txt\", 2013),\n",
    "               (\"PartD_Prescriber_PUF_NPI_Drug_14.txt\", 2014),\n",
    "               (\"PartD_Prescriber_PUF_NPI_Drug_15.txt\", 2015),\n",
    "               (\"PartD_Prescriber_PUF_NPI_Drug_16.txt\", 2016)]\n",
    "\n",
    "df_list = []\n",
    "for path in path_tuples:\n",
    "    data_key = path[0] # Where the file is within your bucket\n",
    "    data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "    df_list.append(process_partD(data_location, path[1]))\n",
    "df = pd.concat(df_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>nppes_provider_last_org_name</th>\n",
       "      <th>nppes_provider_first_name</th>\n",
       "      <th>nppes_provider_city</th>\n",
       "      <th>nppes_provider_state</th>\n",
       "      <th>specialty_description</th>\n",
       "      <th>description_flag</th>\n",
       "      <th>drug_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>bene_count</th>\n",
       "      <th>...</th>\n",
       "      <th>total_day_supply</th>\n",
       "      <th>total_drug_cost</th>\n",
       "      <th>bene_count_ge65</th>\n",
       "      <th>bene_count_ge65_suppress_flag</th>\n",
       "      <th>total_claim_count_ge65</th>\n",
       "      <th>ge65_suppress_flag</th>\n",
       "      <th>total_30_day_fill_count_ge65</th>\n",
       "      <th>total_day_supply_ge65</th>\n",
       "      <th>total_drug_cost_ge65</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>ENKESHAFI</td>\n",
       "      <td>ARDALAN</td>\n",
       "      <td>CUMBERLAND</td>\n",
       "      <td>MD</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>S</td>\n",
       "      <td>ISOSORBIDE MONONITRATE ER</td>\n",
       "      <td>ISOSORBIDE MONONITRATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>307</td>\n",
       "      <td>171.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>ENKESHAFI</td>\n",
       "      <td>ARDALAN</td>\n",
       "      <td>CUMBERLAND</td>\n",
       "      <td>MD</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>S</td>\n",
       "      <td>LEVOFLOXACIN</td>\n",
       "      <td>LEVOFLOXACIN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>227.10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>159.72</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>ENKESHAFI</td>\n",
       "      <td>ARDALAN</td>\n",
       "      <td>CUMBERLAND</td>\n",
       "      <td>MD</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>S</td>\n",
       "      <td>LISINOPRIL</td>\n",
       "      <td>LISINOPRIL</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>570</td>\n",
       "      <td>100.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>ENKESHAFI</td>\n",
       "      <td>ARDALAN</td>\n",
       "      <td>CUMBERLAND</td>\n",
       "      <td>MD</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>S</td>\n",
       "      <td>METOPROLOL TARTRATE</td>\n",
       "      <td>METOPROLOL TARTRATE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>916</td>\n",
       "      <td>154.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>ENKESHAFI</td>\n",
       "      <td>ARDALAN</td>\n",
       "      <td>CUMBERLAND</td>\n",
       "      <td>MD</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>S</td>\n",
       "      <td>PREDNISONE</td>\n",
       "      <td>PREDNISONE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>44.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          npi nppes_provider_last_org_name nppes_provider_first_name  \\\n",
       "0  1003000126                    ENKESHAFI                   ARDALAN   \n",
       "1  1003000126                    ENKESHAFI                   ARDALAN   \n",
       "2  1003000126                    ENKESHAFI                   ARDALAN   \n",
       "3  1003000126                    ENKESHAFI                   ARDALAN   \n",
       "4  1003000126                    ENKESHAFI                   ARDALAN   \n",
       "\n",
       "  nppes_provider_city nppes_provider_state specialty_description  \\\n",
       "0          CUMBERLAND                   MD     Internal Medicine   \n",
       "1          CUMBERLAND                   MD     Internal Medicine   \n",
       "2          CUMBERLAND                   MD     Internal Medicine   \n",
       "3          CUMBERLAND                   MD     Internal Medicine   \n",
       "4          CUMBERLAND                   MD     Internal Medicine   \n",
       "\n",
       "  description_flag                  drug_name            generic_name  \\\n",
       "0                S  ISOSORBIDE MONONITRATE ER  ISOSORBIDE MONONITRATE   \n",
       "1                S               LEVOFLOXACIN            LEVOFLOXACIN   \n",
       "2                S                 LISINOPRIL              LISINOPRIL   \n",
       "3                S        METOPROLOL TARTRATE     METOPROLOL TARTRATE   \n",
       "4                S                 PREDNISONE              PREDNISONE   \n",
       "\n",
       "   bene_count  ...   total_day_supply  total_drug_cost  bene_count_ge65  \\\n",
       "0         NaN  ...                307           171.59              NaN   \n",
       "1        26.0  ...                165           227.10             15.0   \n",
       "2        17.0  ...                570           100.37              NaN   \n",
       "3        28.0  ...                916           154.65              NaN   \n",
       "4        14.0  ...                133            44.72              NaN   \n",
       "\n",
       "   bene_count_ge65_suppress_flag  total_claim_count_ge65 ge65_suppress_flag  \\\n",
       "0                              *                     NaN                  *   \n",
       "1                            NaN                    15.0                NaN   \n",
       "2                              #                     NaN                  #   \n",
       "3                              #                     NaN                  #   \n",
       "4                              *                     NaN                  *   \n",
       "\n",
       "   total_30_day_fill_count_ge65 total_day_supply_ge65  total_drug_cost_ge65  \\\n",
       "0                           NaN                   NaN                   NaN   \n",
       "1                          15.0                 106.0                159.72   \n",
       "2                           NaN                   NaN                   NaN   \n",
       "3                           NaN                   NaN                   NaN   \n",
       "4                           NaN                   NaN                   NaN   \n",
       "\n",
       "   year  \n",
       "0  2013  \n",
       "1  2013  \n",
       "2  2013  \n",
       "3  2013  \n",
       "4  2013  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv from efs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique ids\n",
    "unique_id = np.array(list(set(zip(df[\"npi\"].values,\n",
    "                                  df[\"nppes_provider_last_org_name\"].values, \n",
    "                                  df[\"nppes_provider_first_name\"].values,\n",
    "                                  df[\"specialty_description\"].values,\n",
    "                                  df[\"nppes_provider_city\"].values,\n",
    "                                  df[\"nppes_provider_state\"].values)))).T\n",
    "id_df = pd.DataFrame(unique_id.T, columns=[\"npi\",\"last/org name\",\"first name\",\"specialty\",\"city\",\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>last/org name</th>\n",
       "      <th>first name</th>\n",
       "      <th>specialty</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1164674164</td>\n",
       "      <td>CURRY</td>\n",
       "      <td>BROOKE</td>\n",
       "      <td>Physician Assistant</td>\n",
       "      <td>SCOTLAND NECK</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1871564039</td>\n",
       "      <td>SHEIKH</td>\n",
       "      <td>FAREED</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1609031426</td>\n",
       "      <td>CASTLE</td>\n",
       "      <td>KENNETH</td>\n",
       "      <td>Dentist</td>\n",
       "      <td>KAPAA</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1538272257</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>RONALD</td>\n",
       "      <td>Allergy/ Immunology</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1326091547</td>\n",
       "      <td>HAVEN</td>\n",
       "      <td>JESSE</td>\n",
       "      <td>Family Practice</td>\n",
       "      <td>NAPLES</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          npi last/org name first name            specialty           city  \\\n",
       "0  1164674164         CURRY     BROOKE  Physician Assistant  SCOTLAND NECK   \n",
       "1  1871564039        SHEIKH     FAREED           Cardiology      LAS VEGAS   \n",
       "2  1609031426        CASTLE    KENNETH              Dentist          KAPAA   \n",
       "3  1538272257         BROWN     RONALD  Allergy/ Immunology          DAVIS   \n",
       "4  1326091547         HAVEN      JESSE      Family Practice         NAPLES   \n",
       "\n",
       "  state  \n",
       "0    NC  \n",
       "1    NV  \n",
       "2    HI  \n",
       "3    CA  \n",
       "4    FL  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: what will the a feature matrix look like\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's going to be in the rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = list(set(zip(*id_df.drop(columns=['npi']).as_matrix().T.tolist())))\n",
    "unique_names = list(set(zip(*id_df[['last/org name','first name']].as_matrix().T.tolist())))\n",
    "print(\"length of unique items: \",id_df.shape[0])\n",
    "print(\"length of unique ids: \",len(unique_ids))\n",
    "print(\"length of unique names: \",len(unique_names))\n",
    "print(\"length of unique npi: \", len(set(id_df['npi'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We're going to go with unique npis in the rows for now!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=['nppes_provider_last_org_name',\n",
    "                       'nppes_provider_first_name',\n",
    "                       'nppes_provider_city',\n",
    "                       'nppes_provider_state',\n",
    "                       'specialty_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's going to be in the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_generic_names = list(set(df1[\"generic_name\"].values))\n",
    "unique_drug_names = list(set(df1[\"drug_name\"].values))\n",
    "print(\"number of unique drugs by generic_name: \", len(unique_generic_names))\n",
    "print(\"number of unique drugs by drug_name: \", len(unique_drug_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We're going to go with generic_name in the columns for now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(columns=['drug_name'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_flags = list(set(df2['description_flag'].values))\n",
    "bene_count_ge65_suppress_flags = list(set(df2['bene_count_ge65_suppress_flag'].values))\n",
    "ge65_suppress_flags = list(set(df2['ge65_suppress_flag'].values))\n",
    "print('description_flags: ', description_flags)\n",
    "print('bene_count_ge65_suppress_flags: ', bene_count_ge65_suppress_flags)\n",
    "print('ge65_suppress_flags: ', ge65_suppress_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We're going to drop `description_flag`,`bene_count_ge65_suppress_flags`,and `ge65_suppress_flags`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(columns=['description_flag','bene_count_ge65_suppress_flag','ge65_suppress_flag'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start building the matrix\n",
    "> 1. merge npi and year\n",
    "> 2. build feature matrix\n",
    "> 3. split feature matrix by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging npi and year\n",
    "df3['year'] = pd.to_numeric(df3['year'])\n",
    "df3['year_npi'] = list(zip(*df3[['year','npi']].as_matrix().T.astype(str)))\n",
    "\n",
    "# drop year and npi\n",
    "df4 = df3.drop(columns=[\"npi\",\"year\"])\n",
    "del df, df1, df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dataframe\n",
    "df = df4[['year_npi','generic_name',\n",
    "          'bene_count',\n",
    "          'total_claim_count',\n",
    "          'total_30_day_fill_count',\n",
    "          'total_day_supply',\n",
    "          'total_drug_cost',\n",
    "          'bene_count_ge65',\n",
    "          'total_claim_count_ge65',\n",
    "          'total_30_day_fill_count_ge65',\n",
    "          'total_day_supply_ge65',\n",
    "          'total_drug_cost_ge65']].groupby(['year_npi','generic_name']).agg('sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bene_count = df.pivot(index='year_npi', columns='generic_name', values='bene_count')\n",
    "df_bene_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bene_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_size = df_bene_count.memory_usage()[0] * df_bene_count.shape[1]\n",
    "print('bene_count sparse matrix size: {} GiB'.format(round(mat_size/(10**9),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have 10 distict explicit data fields from Medicare Part D and we can also, derive the following implicit data fields:**\n",
    "> - Drug cost per beneficiary\n",
    "> - Drug cost per claim\n",
    "> - Drug cost per beneficiary ge_65\n",
    "> - Drug cost per claim ge_65\n",
    "> - Relative distribution of drug cost as a percentage of total\n",
    "\n",
    "**_All in, that's about 15 data fields or 817.5 GiB of sparse matrices!!!_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Building the Machine Learning Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Modeling Pipeline:\n",
    "> 1. Build out all explicit and implicit feature matrices\n",
    "> 2. Train models using regressors for each feature matrix\n",
    "> 3. Pass probabilities from each model into a master matrix\n",
    "> 4. Train master model\n",
    "\n",
    "**_Given that each feature matrix is for a specific data field, I expect the results of the model to be highly interpretable_**\n",
    "\n",
    "> **Concerns:** There are 3,405,384 unique records (year_npi) and only 2,879 targets (excluded individuals with NPI numbers) over the same period.<br>\n",
    "> **Solution Strategy:** Perform a Chi-Squared test to determine how independant are the 15 features from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# save unique ids file\n",
    "start_time = time.time()\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'bene_count.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "del df\n",
    "end_time = time.time()\n",
    "print(\"time elapsed: \", end_time-start_time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-1f58bea52b26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtotal_drug_cost_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year_npi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'generic_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'total_drug_cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbene_count_ge65_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year_npi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'generic_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bene_count_ge65'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtotal_claim_count_ge65_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year_npi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'generic_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'total_claim_count_ge65'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtotal_30_day_fill_count_ge65_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year_npi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'generic_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'total_30_day_fill_count_ge65'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtotal_day_supply_ge65_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year_npi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'generic_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'total_day_supply_ge65'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   2149\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   2151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4262\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4263\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4264\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   4144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m             new_blocks = self._slice_take_blocks_ax0(indexer,\n\u001b[0;32m-> 4146\u001b[0;31m                                                      fill_tuple=(fill_value,))\n\u001b[0m\u001b[1;32m   4147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4148\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[1;32m   4224\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[1;32m   4225\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4226\u001b[0;31m                                               fill_tuple=None))\n\u001b[0m\u001b[1;32m   4227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1217\u001b[0;31m                                        allow_fill=False)\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "bene_count_df = df4[['year_npi','generic_name','bene_count']]\n",
    "total_claim_count_df = df4[['year_npi','generic_name','total_claim_count']]\n",
    "total_30_day_fill_count_df = df4[['year_npi','generic_name','total_30_day_fill_count']]\n",
    "total_day_supply_df = df4[['year_npi','generic_name','total_day_supply']]\n",
    "total_drug_cost_df = df4[['year_npi','generic_name','total_drug_cost']]\n",
    "bene_count_ge65_df = df4[['year_npi','generic_name','bene_count_ge65']]\n",
    "total_claim_count_ge65_df = df4[['year_npi','generic_name','total_claim_count_ge65']]\n",
    "total_30_day_fill_count_ge65_df = df4[['year_npi','generic_name','total_30_day_fill_count_ge65']]\n",
    "total_day_supply_ge65_df = df4[['year_npi','generic_name','total_day_supply_ge65']]\n",
    "total_drug_cost_ge65_df = df4[['year_npi','generic_name','total_drug_cost_ge65']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]-df3[pd.isnull(df3['year'])].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2013' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-45fea6f1fbf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2013\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2013' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
