{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce dimensions\n",
    "---\n",
    "> 1. Load and prep data\n",
    "> 2. Focus on prescriptions that make up a significant annual dollar volume per prescriber\n",
    "> 3. Focus on states with highest exclusion rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.24.0)\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from multiprocessing import Pool\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import itertools\n",
    "\n",
    "# import own scripts\n",
    "import sys\n",
    "sys.path.insert(0, '/healthcare-fraud/src/')\n",
    "import scripts as src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = src.read_from_efs('df_trgt.csv')\n",
    "print('df shape: ', LEIE.shape)\n",
    "excl_npi = LEIE['npi'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = src.read_from_efs('df.csv')\n",
    "print('df shape: ', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi = df['npi'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(excl_npi).intersection(set(npi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_clean = src.read_from_efs('df_clean.csv')\n",
    "\n",
    "print('df_clean shape: ', df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_excl = df_clean['npi'][df_clean['excluded']].drop_duplicates()\n",
    "npi_ok = df_clean['npi'][~df_clean['excluded']].drop_duplicates()\n",
    "print(len(npi_excl), len(npi_ok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude extremely rare prescriptions\n",
    "---\n",
    "> It's reasonable to use `total_30_day_fill_count` and `total_30_day_fill_count_ge65`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean nans and infs and convert to values\n",
    "X = X.fillna(0).replace(np.inf, 0)\n",
    "\n",
    "generic_name_cnt = X.groupby('generic_name').agg('sum').reset_index()[['generic_name',\n",
    "                                                                       'total_30_day_fill_count',\n",
    "                                                                       'total_30_day_fill_count_ge65']]\n",
    "\n",
    "generic_name_cnt['sum'] = generic_name_cnt['total_30_day_fill_count'] + generic_name_cnt['total_30_day_fill_count_ge65']\n",
    "\n",
    "generic_name_cnt.sort_values(by='sum', ascending=False, inplace=True)\n",
    "generic_name_cnt.reset_index(drop=True, inplace=True)\n",
    "print('generic_name_cnt shape: ', generic_name_cnt.shape)\n",
    "generic_name_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generic_name_cnt['sum']\n",
    "threshold = 250\n",
    "src.log_plot(data, threshold,'Prescription count `generic_name` in descending order', \\\n",
    "         'Prescription Count', 'generic_name', logx=True, logy=True, figsize=(8,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_drugs = generic_name_cnt['generic_name'][:threshold]\n",
    "\n",
    "# get indeces for target_drugs\n",
    "def find_drug_index(drug):\n",
    "    return X[X['generic_name']==drug].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of available CPU cores: \")\n",
    "!cat /proc/cpuinfo | grep processor | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find target indeces for target drugs using multiprocessing\n",
    "processors = 64\n",
    "if __name__ == '__main__':\n",
    "    tasks = target_drugs\n",
    "    function = find_drug_index\n",
    "    with Pool(processes=processors)as p:\n",
    "        results = list(tqdm_notebook(p.imap(function, tasks), total=len(tasks)))\n",
    "        \n",
    "trgt_idx = list(itertools.chain(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild data with target `generic_names`\n",
    "df_id_250drugs = df_id.iloc[trgt_idx].reset_index(drop=True)\n",
    "print(\"df_id_250drugs shape: \", df_id_250drugs.shape)\n",
    "df_id_250drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_250drugs = X.iloc[trgt_idx].reset_index(drop=True)\n",
    "print(\"X_250drugs shape: \", X_250drugs.shape)\n",
    "\n",
    "y_250drugs = y.iloc[trgt_idx].reset_index(drop=True)\n",
    "print(\"y_250drugs shape: \", y_250drugs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_250drugs = df_id_250drugs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_250drugs = X_250drugs.reset_index(drop=True)\n",
    "y_250drugs = y_250drugs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Label Data (y)**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('y shape: ', y.shape)\n",
    "# y.head()\n",
    "del df_id, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus on states with highest exclusion rates\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label\n",
    "df_id_250drugs['exclusion'] = y_250drugs\n",
    "\n",
    "# count `exclusion by state`\n",
    "exclusions_by_state = df_id_250drugs[['nppes_provider_state','exclusion']].groupby('nppes_provider_state').agg('sum')\\\n",
    "                                                             .sort_values('exclusion', ascending=False).astype(int)\n",
    "\n",
    "# count Medicare Part D `providers by state`\n",
    "providers_by_state = df_id_250drugs[['nppes_provider_state','npi']].groupby('nppes_provider_state').agg('count')\\\n",
    "                                                             .sort_values('npi', ascending=False).astype(int)\n",
    "\n",
    "# join `exclusion by state` and `providers by state`\n",
    "counts_by_state = providers_by_state.join(exclusions_by_state)\n",
    "\n",
    "# calculate `exclusion ratio`\n",
    "counts_by_state['exclusion_ratio'] = counts_by_state['exclusion']/counts_by_state['npi']\n",
    "counts_by_state.sort_values('exclusion_ratio', ascending=False, inplace=True)\n",
    "counts_by_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build `state_ratio_df` with cummulatives\n",
    "state_ratio_df = pd.DataFrame()\n",
    "state_ratio_df['cumm_provider_cnt'] = counts_by_state['npi'].cumsum()\n",
    "state_ratio_df['cumm_exclusion_cnt'] = counts_by_state['exclusion'].cumsum()\n",
    "state_ratio_df['exclusion_ratio'] = state_ratio_df['cumm_exclusion_cnt']/state_ratio_df['cumm_provider_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sorted cumulative chart by Exclusion Ratio\n",
    "threshold_value=20\n",
    "src.plot_multi(state_ratio_df, threshold_value, 'States', figsize=(8,5), title='Exclusion ratio sorted by State')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_states = state_ratio_df.index[:threshold_value].tolist()\n",
    "print('Top states by exclusion ratio: ', top_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indeces for target_drugs\n",
    "def find_state_index(state):\n",
    "    return df_id_250drugs[df_id_250drugs['nppes_provider_state']==state].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find target indeces for target states using multiprocessing\n",
    "processors = 64\n",
    "if __name__ == '__main__':\n",
    "    tasks = target_states\n",
    "    function = find_state_index\n",
    "    with Pool(processes=processors)as p:\n",
    "        results = list(tqdm_notebook(p.imap(function, tasks), total=len(tasks)))\n",
    "        \n",
    "trgt_idx = list(itertools.chain(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data sets by top states\n",
    "df_id_reduced = df_id_250drugs.iloc[trgt_idx].reset_index(drop=True)\n",
    "X_reduced = X_250drugs.iloc[trgt_idx].reset_index(drop=True)\n",
    "y_reduced = y_250drugs.iloc[trgt_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'exclusion' from df_id\n",
    "df_id_reduced.drop('exclusion', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Identification Data (df_id)\n",
    "> for consistancy remove `exclusion` column as a separate `label` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df_id_reduced shape: ', df_id_reduced.shape)\n",
    "df_id_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced Feature Matrix (X)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_reduced shape: ', X_reduced.shape)\n",
    "X_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced Label Data `y_reduced`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_reduced shape: ', y_reduced.shape)\n",
    "y_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to efs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.save_to_efs(y_reduced,'y_reduced.csv')\n",
    "src.save_to_efs(X_reduced,'X_reduced.csv')\n",
    "src.save_to_efs(df_id_reduced, 'df_id_reduced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
